# Устройство обычной бд
* данные строки хранятся внутри файлов очень близко на физическом уровне
* Преимущества
    - Быстрое обновление, добавление
# Устройство колоночной БД
* наоборот, данные столбца храняться очень близко
* Преимущества
    - крайне быстрое чтение
    - сжатие данных 
        (всё, что похоже друг на друга лежит вместе, за счёт этого
        максимально качественно сжимается)
* Недостатки
    - Медленнее CUD
    - Отсутствие полноценных транзакций
# ClickHouse
- Столбцовая СУБД для онлайн обработки аналитических запросов (OLAP)

## Отличительные возможности
- столбцовая
- сжатие данных
- хранение на диске
- параллельная обработка запроса на многих процессорных ядрах
- распределённая обработка запросов на многих серверах
- обновление данных в онлайн
- наличие индекса
- подходит для онлайн запросов
- поддержка приближенных вычислений
- репликация данных и поддержка целостности
- SQL

## Особенности
- Отсутствие полноценных транзакций
- возможность изменять или удалять ранее записанные данные 
    с низкими задержками и высокой частотой запросов 
    не предоставляется. Есть массовое удаление и изменение(*партицирование)
- Разреженный индекс делает ClickHouse плохо пригодным для
    точечных чтений одиночных строк по своим ключам

## Движки
- Основная идея заложенных в семейство движков семейства MergeTree слудующая.
    Когда у вас огромное количество данных, к-е должны быть вставлены в таблицу 
    вы должны быстро записать их по частям, а затем объединить эти части по 
    некоторым правилам в *фоновом режиме. Этот метод намного эффективнее,
    чем постоянная перезапись данных в хранилище при вставке
* Merge Tree
    - хранит данные, отсортированные по первичному ключу
    - позволяет оперировать партициями, если задан ключ партицирования
    - поддерживает репликацию данных
    - поддерживает сэмплирование данных
- (Log) Движки разработаны для сценариев, когда необходимо быстро записывать
    много таблиц с небольшим объёмом данных (менее 1 миллиона строк),
    а затем читать их целиком
* Log
    - Хранят данные на диске
    - Добавляют данные в конце файла при записи
    - Не поддерживают операции мутации(записали-считали всё)
    - Не поддерживают индексы
    - Записывают данные не атомарно

### Типы MergeTree
- ReplacingMT: выполняет удаление дублирующихся записей с одинаковым
    значением ключа сортировки
- SummingMT: все строки с одинаковым ключём сортировки заменяет
    на одну, которая хранит только суммы значений из столбцов
    с цифровым типом данных
- CollapsingMT: асинхронно удаляет (сворачивает) пары строк, если
    все поля в ключе сортировки (ORDER BY) эквиваленты, за исключением
    специального поля Sign, к-е может принимать значение 1 и -1

```SQL 
--ClickHouseSQL
CREATE TABLE [IF NOT EXISTS] db.table_name (
    model_id UInt32,
    model_name String,
    release_year UInt16,
    engine_type String,
    horsepower UInt16,
    price Decimal(10, 2)
) 
ENGINE = MergeTree() ORDER BY model_id;
PARTITION = 
TTL =
... 
```

## Первичный ключ и ключ сортировки
```SQL
ORDER BY(CounterID, Date)
```
- Таблица состоит из кусков данных(data parts), отсортированных по первичному ключу
- При вставке создаются отдельные куски данных, каждый из которых лексикографически
    отсортирован по PK
- Каждый кусок данных делится на гранулы
- Гранула - минимальный неделимый набор данных, 
    к-й ClickHouse считывает при выборке данных
    (*можно извлекать только гарнулами см. Пример запроса)
- Первая строка гранулы помечается значение PK для этой строки(засечка)
* Обобщение, наглядный пример см. "пк order by w e g"

* Существует возможность задать PK (выражение, значения 
    к-го будут записаны в индексный файл для каждой засечки),
    отличный от ключа сортировки (выражение по к-му будут упорядочены
    строки в кусках данных)
    - Кортеж выражения первичного ключа при этом должен быть префиксом
        выражения ключа сортировки
    - Данная возможность особенно полезна при использовании движков
        SummingMT и AggregationMT
## Партиционирование
* Партиция - набор записей в таблице, объединённых по к-му-либо критерию
    - Взаимодействовать с ними на CRUD не можем - чисто механизм хранения
        - *ClickHouse говорит, что не стоит превышать 1000 партиций на таблицу
        - Образно говоря старые данные, например 10-летней давности, 
            можно удалить одним запросом(крупными кусками данные удалять можно)
    - Например, партиция мб по месяцу, по дню или по типу события.
        Данные для разных партиций хранятся отдельно
    - Это позволяет оптимизировать работу с данными, т.к. при обработке
        запросов будет использоваться только необходимое подмножество
        из всевозможных данных
        - Например, при получении данных за определённый месяц
        ClickHouse будет считывать данные только за этот месяц
        - Данные относящиеся к разным партициям разбиваются на
            разные куски 
## Select - непонятные и понятные слова
- WITH
- ARRAY JOIN/JOIN'ы
- SAMPLE
- WHERE/PREWHERE
- GROUP/HAVING
- ORDER
- LIMIT *нет оффсетов, задаётся в LIMIT через запятую
- INTO
- FORMAT
- INSERT

### INSERT
- сортирует входящие данные по PK и разбивает их 
    на партиции по ключу партицирования(далее KP)
    - Добавлять данные большими пачками, например, по 100000 строк
        * люди обычно ставят перед ClickH кафку или кролика,
            чтобы они собирали данные пачками и далее отдавали ему
            (*логично, ведь кафка бай дэфолт ждёт переполнения batch
            на продюссерах и только потом отправляет данные в заранее
            известных брокера и партицию)
    - Группировать данные по KP самостоятельно перед загрузкой
- Снижения производительности не будет, если:
    - данные поступают в режиме онлайн
        - *например, отсортированы по дате - пишутся тупо в хвост
    - загружаем данные, к-е (обычно), как правило
        отсортированы по времени

### ALTER - см "alter"
- Работа с колонками(ADD/DROP/CLEAR/MODIFY COLUMN)
- С индексами
- С ограничениями
- С партициями - см "alter"

# Пример
## Задача: 
    Собираем логи с наших приложений:
    - Дата/время записи
    - ИД приложения
    - Наименование логгера
    - Версия логгера
    - Уровень лога
    - Сообщение
* Создаём таблицу? - нет.
- Узнаём задачи, к-е будет решать наше приложение
## Задача приложения
- Получение логов за последние n дней по конкретному приложению - часто
- Выведение списка приложений с указанием сколько логов прилетело
    за последние n дней с группировкой по статусу (очень часто):
    - Сантехник: DEBUG - 1443, Error - 22
    - КайзерДом: DEBUG - 1443, Warn-23, Error - 3
- Выведение графика по отдельному проекту - очень часто
    - ось x - дни
    - ось y - количество
    - линии - каждый из уровней лога... to be continued